{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "1. В коде из методички реализуйте один или несколько критериев останова: количество листьев, количество используемых признаков, глубина дерева и т. д."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from sklearn import datasets\n",
    "from sklearn import model_selection"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "class Leaf:\n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        classes = {}\n",
    "        for label in self.labels:\n",
    "            if label not in classes:\n",
    "                classes[label] = 0\n",
    "            classes[label] += 1\n",
    "        prediction = max(classes, key=classes.get)\n",
    "        return prediction\n",
    "    \n",
    "\n",
    "def gini(labels):\n",
    "    classes = {}\n",
    "    for label in labels:\n",
    "        if label not in classes:\n",
    "            classes[label] = 0\n",
    "        classes[label] += 1\n",
    "    impurity = 1\n",
    "    for label in classes:\n",
    "        p = classes[label] / len(labels)\n",
    "        impurity -= p**2\n",
    "    return impurity\n",
    "\n",
    "\n",
    "def quality(left_labels, right_labels, current_gini):\n",
    "    p = float(left_labels.shape[0] / (left_labels.shape[0] + right_labels.shape[0]))\n",
    "    return current_gini - p * gini(left_labels) - (1 - p) * gini(right_labels)\n",
    "\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "\n",
    "def find_best_split(data, labels, min_leaf):\n",
    "    current_gini = gini(labels)\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    n_features = data.shape[1]\n",
    "    for index in range(n_features):\n",
    "        t_values = np.unique([row[index] for row in data])\n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            current_quality = quality(true_labels, false_labels, current_gini)\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "\n",
    "def build_tree(data, labels, min_leaf=5, max_depth=3):\n",
    "    quality, t, index = find_best_split(data, labels, min_leaf)\n",
    "    if quality == 0 or max_depth < 1:\n",
    "        return Leaf(data, labels)\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "    max_depth -= 1\n",
    "    true_branch = build_tree(true_data, true_labels, min_leaf, max_depth)\n",
    "    false_branch = build_tree(false_data, false_labels, min_leaf, max_depth)\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "\n",
    "def classify_object(obj, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)\n",
    "    \n",
    "\n",
    "def predict(data, tree):\n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def print_tree(node, spacing=\"\"):\n",
    "\n",
    "    # Если лист, то выводим его прогноз\n",
    "    if isinstance(node, Leaf):\n",
    "        print(spacing + \"Прогноз:\", node.prediction)\n",
    "        return\n",
    "\n",
    "    # Выведем значение индекса и порога на этом узле\n",
    "    print(spacing + 'Индекс', str(node.index))\n",
    "    print(spacing + 'Порог', str(node.t))\n",
    "\n",
    "    # Рекурсионный вызов функции на положительном поддереве\n",
    "    print (spacing + '--> True:')\n",
    "    print_tree(node.true_branch, spacing + \"  \")\n",
    "\n",
    "    # Рекурсионный вызов функции на положительном поддереве\n",
    "    print (spacing + '--> False:')\n",
    "    print_tree(node.false_branch, spacing + \"  \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# сгенерируем данные\n",
    "classification_data, classification_labels = datasets.make_classification(n_features = 2, n_informative = 2, \n",
    "                                                      n_classes = 2, n_redundant=0, \n",
    "                                                      n_clusters_per_class=1, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data, test_data, train_labels, test_labels = model_selection.train_test_split(classification_data, classification_labels, test_size = 0.3, random_state = 1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(train_data, train_labels, max_depth=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0\n",
      "Порог 0.16261402870113306\n",
      "--> True:\n",
      "  Индекс 1\n",
      "  Порог -1.5208896621663803\n",
      "  --> True:\n",
      "    Индекс 0\n",
      "    Порог -0.9478301462477035\n",
      "    --> True:\n",
      "      Прогноз: 0\n",
      "    --> False:\n",
      "      Прогноз: 1\n",
      "  --> False:\n",
      "    Прогноз: 0\n",
      "--> False:\n",
      "  Прогноз: 1\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "2. Реализуйте дерево для задачи регрессии. Возьмите за основу дерево, реализованное в методичке, заменив механизм предсказания в листе на взятие среднего значения по выборке, и критерий Джини на дисперсию значений.\n",
    "Комментарий:\n",
    "Критерий останова \"глубина дерева\" я реализовал не в коде из методички, а уже в измененном коде для задачи регрессии. На суть это не влияет, поскольку функция build_tree не зависит от особенностей решаемой задачи (она просто строит дерево и ничего не знает о контексте)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Node:\n",
    "\n",
    "    def __init__(self, index, t, true_branch, false_branch):\n",
    "        self.index = index\n",
    "        self.t = t\n",
    "        self.true_branch = true_branch\n",
    "        self.false_branch = false_branch\n",
    "\n",
    "class Leaf:\n",
    "\n",
    "    def __init__(self, data, labels):\n",
    "        self.data = data\n",
    "        self.labels = labels\n",
    "        self.prediction = self.predict()\n",
    "\n",
    "\n",
    "    def predict(self):\n",
    "        return self.labels.mean()\n",
    "    \n",
    "\n",
    "def mse(labels):\n",
    "    return np.mean((labels - labels.mean())**2)\n",
    "\n",
    "\n",
    "def quality(left_labels, right_labels, root_criterion, criterion):\n",
    "    p = float(left_labels.shape[0] / (left_labels.shape[0] + right_labels.shape[0]))\n",
    "    return root_criterion - p * criterion(left_labels) - (1 - p) * criterion(right_labels)\n",
    "\n",
    "\n",
    "def split(data, labels, index, t):\n",
    "    left = np.where(data[:, index] <= t)\n",
    "    right = np.where(data[:, index] > t)\n",
    "    true_data = data[left]\n",
    "    false_data = data[right]\n",
    "    true_labels = labels[left]\n",
    "    false_labels = labels[right]\n",
    "    return true_data, false_data, true_labels, false_labels\n",
    "\n",
    "\n",
    "def find_best_split(data, labels, min_leaf):\n",
    "    root_mse = mse(labels)\n",
    "    best_quality = 0\n",
    "    best_t = None\n",
    "    best_index = None\n",
    "    n_features = data.shape[1]\n",
    "    for index in range(n_features):\n",
    "        t_values = np.unique([row[index] for row in data])\n",
    "        for t in t_values:\n",
    "            true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "            if len(true_data) < min_leaf or len(false_data) < min_leaf:\n",
    "                continue\n",
    "            current_quality = quality(true_labels, false_labels, root_mse, mse)\n",
    "            if current_quality > best_quality:\n",
    "                best_quality, best_t, best_index = current_quality, t, index\n",
    "    return best_quality, best_t, best_index\n",
    "\n",
    "\n",
    "def build_tree(data, labels, min_leaf=5):\n",
    "    quality, t, index = find_best_split(data, labels, min_leaf)\n",
    "    if quality == 0:\n",
    "        return Leaf(data, labels)\n",
    "    true_data, false_data, true_labels, false_labels = split(data, labels, index, t)\n",
    "    true_branch = build_tree(true_data, true_labels, min_leaf)\n",
    "    false_branch = build_tree(false_data, false_labels, min_leaf)\n",
    "    return Node(index, t, true_branch, false_branch)\n",
    "\n",
    "\n",
    "def classify_object(obj, node):\n",
    "    if isinstance(node, Leaf):\n",
    "        answer = node.prediction\n",
    "        return answer\n",
    "    if obj[node.index] <= node.t:\n",
    "        return classify_object(obj, node.true_branch)\n",
    "    else:\n",
    "        return classify_object(obj, node.false_branch)\n",
    "    \n",
    "\n",
    "def predict(data, tree):\n",
    "    classes = []\n",
    "    for obj in data:\n",
    "        prediction = classify_object(obj, tree)\n",
    "        classes.append(prediction)\n",
    "    return classes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "data, y = datasets.make_regression(n_features=2, n_informative=2, random_state=5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data_regr, test_data_regr, train_y_regr, test_y_regr = model_selection.train_test_split(data, y, test_size=0.3, random_state=1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_tree = build_tree(train_data_regr, train_y_regr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Индекс 0\n",
      "Порог -0.10061434630710828\n",
      "--> True:\n",
      "  Индекс 0\n",
      "  Порог -0.8568531547160899\n",
      "  --> True:\n",
      "    Прогноз: -109.75655471490919\n",
      "  --> False:\n",
      "    Индекс 0\n",
      "    Порог -0.5732155560138283\n",
      "    --> True:\n",
      "      Прогноз: -54.35634172577482\n",
      "    --> False:\n",
      "      Индекс 1\n",
      "      Порог -0.3058530211666308\n",
      "      --> True:\n",
      "        Прогноз: -29.105630694331246\n",
      "      --> False:\n",
      "        Прогноз: -10.772916465924025\n",
      "--> False:\n",
      "  Индекс 0\n",
      "  Порог 0.9068894675659355\n",
      "  --> True:\n",
      "    Индекс 1\n",
      "    Порог 0.6566194702604272\n",
      "    --> True:\n",
      "      Индекс 1\n",
      "      Порог -1.0650326193820066\n",
      "      --> True:\n",
      "        Прогноз: 7.798014762375311\n",
      "      --> False:\n",
      "        Индекс 0\n",
      "        Порог 0.41367880834311616\n",
      "        --> True:\n",
      "          Прогноз: 17.019366109004093\n",
      "        --> False:\n",
      "          Прогноз: 35.95087900163848\n",
      "    --> False:\n",
      "      Индекс 0\n",
      "      Порог 0.34691932708774675\n",
      "      --> True:\n",
      "        Прогноз: 37.4238776327042\n",
      "      --> False:\n",
      "        Прогноз: 61.9558421220885\n",
      "  --> False:\n",
      "    Индекс 0\n",
      "    Порог 1.3348485742415819\n",
      "    --> True:\n",
      "      Прогноз: 77.83232966482356\n",
      "    --> False:\n",
      "      Прогноз: 123.1031262020856\n"
     ]
    }
   ],
   "source": [
    "print_tree(my_tree)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.6"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
